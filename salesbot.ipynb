{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f56963-316e-48ea-a93b-164589ec2eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running. Version: 0.6.5\n",
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import gradio as gr\n",
    "\n",
    "# Ollama API setup\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "OLLAMA_MODEL = \"llama3.2\"\n",
    "\n",
    "# Check if Ollama is running\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:11434/api/version\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Ollama is running. Version: {response.json().get('version', 'unknown')}\")\n",
    "    else:\n",
    "        print(\"Ollama is available but returning unexpected response\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Warning: Ollama server not detected at http://localhost:11434\")\n",
    "    print(\"Make sure Ollama is running before using this application\")\n",
    "\n",
    "# System prompt\n",
    "system_message = \"\"\"You are a helpful assistant in a clothes store. You should try to gently encourage \n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \n",
    "For example, if the customer says 'I'm looking to buy a hat', \n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\n",
    "Encourage the customer to buy hats if they are unsure what to get.\n",
    "If the customer asks for shoes, you should respond that shoes are not on sale today, \n",
    "but remind the customer to look at hats!\n",
    "\"\"\"\n",
    "\n",
    "def chat(message, history):\n",
    "    # Add context if belts are mentioned\n",
    "    relevant_system_message = system_message\n",
    "    if 'belt' in message.lower():\n",
    "        relevant_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
    "\n",
    "    # Prepare messages for Ollama API\n",
    "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}]\n",
    "    messages.extend(history) #all previous messages (history) in OpenAI-style roles: \"user\" / \"assistant\"\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # Send POST request to Ollama's chat endpoint\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_API, json={\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"messages\": messages,\n",
    "            \"stream\": False\n",
    "        })\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            reply = response.json()[\"message\"][\"content\"]\n",
    "            yield reply\n",
    "        else:\n",
    "            yield f\"Error: Received status code {response.status_code} from Ollama.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        yield f\"Request failed: {e}\"\n",
    "\n",
    "# Launch Gradio UI\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d819d-84a3-4d4b-895d-9fed3015c8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
